{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphRec2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJQhAjOqeZjeNWJfNmjs3A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wwangwe/Un-supervised-Machine-Learning/blob/master/GraphRec2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4urRs6yLcLF"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouHHjqD_IuUJ"
      },
      "source": [
        "import torch #Open Source ML library\n",
        "import torch.nn as nn #Building Block for Neural Networks\n",
        "from torch.nn import init #Initialize Neural Network Weights\n",
        "from torch.autograd import Variable #Calculates derivatives of Gradients\n",
        "import pickle #Implements Binary Protocols For Serilizing and Deserializing Protocols\n",
        "import numpy as np #Numerical processing Library For Working with Arrays and Linear Agebra Functions\n",
        "import torch.nn.functional as F #Has Useful functions such as activation function \n",
        "import torch.utils.data #Helps in loading data and iterating, batching and any other processes\n",
        "from sklearn.metrics import mean_squared_error # The Square of the error between actual and Predicted values\n",
        "from sklearn.metrics import mean_absolute_error  #The actual values between the predicted and \n",
        "from math import sqrt # A fuction that Returns the square root of a value\n",
        "import datetime #module supplies classes for manipulating dates and times now, past and in future.\n",
        "import argparse #Library for working command line interfaces\n",
        "import os #Licrary for interfacing operating system \n",
        "import random #library of functions that can extend the basic features of python"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIZIJUvYZvId"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjIpHJ-RZ3vq"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, embedding_dims):\n",
        "        super(Attention, self).__init__()\n",
        "        \n",
        "        self.embed_dim = embedding_dims\n",
        "        self.bilinear = nn.Bilinear(self.embed_dim, self.embed_dim, 1)\n",
        "        self.att1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.att2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att3 = nn.Linear(self.embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(0)\n",
        "\n",
        "    def forward(self, node1, u_rep, num_neighs):\n",
        "        uv_reps = u_rep.repeat(num_neighs, 1)\n",
        "        x = torch.cat((node1, uv_reps), 1)\n",
        "        x = F.relu(self.att1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.att2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.att3(x)\n",
        "        att = F.softmax(x, dim=0)\n",
        "        return att"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZKFBLGTPvhn"
      },
      "source": [
        "## UV Aggregator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_MS-K7sPp4-"
      },
      "source": [
        "\n",
        "class UV_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    item and user aggregator: for aggregating embeddings of neighbors (item/user aggreagator).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, v2e, r2e, u2e, embed_dim, cuda=\"cpu\", uv=True):\n",
        "        print(\"UV aggregator\", cuda)\n",
        "        super(UV_Aggregator, self).__init__()\n",
        "        self.uv = uv\n",
        "        self.v2e = v2e\n",
        "        self.r2e = r2e\n",
        "        self.u2e = u2e\n",
        "        self.device = cuda\n",
        "        self.embed_dim = embed_dim\n",
        "        self.w_r1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_r2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_r3 = nn.Linear(self.embed_dim, self.embed_dim) #Optimization Added to enhance MLP of aggregator\n",
        "        #Take an average over the features of multiple elements. However, instead of weighting each element equally, we want to weight them depending on their actual values\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, history_uv, history_r):\n",
        "\n",
        "        embed_matrix = torch.empty(len(history_uv), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "\n",
        "        for i in range(len(history_uv)):\n",
        "            history = history_uv[i]\n",
        "            num_histroy_item = len(history)\n",
        "            tmp_label = history_r[i]\n",
        "\n",
        "            if self.uv == True:\n",
        "                # user component\n",
        "                e_uv = self.v2e.weight[history]\n",
        "                uv_rep = self.u2e.weight[nodes[i]]\n",
        "            else:\n",
        "                # item component\n",
        "                e_uv = self.u2e.weight[history]\n",
        "                uv_rep = self.v2e.weight[nodes[i]]\n",
        "\n",
        "            e_r = self.r2e.weight[tmp_label]\n",
        "            x = torch.cat((e_uv, e_r), 1)\n",
        "            x = F.relu(self.w_r1(x))\n",
        "            o_history = F.relu(self.w_r2(x))\n",
        "\n",
        "            att_w = self.att(o_history, uv_rep, num_histroy_item)\n",
        "            att_history = torch.mm(o_history.t(), att_w)\n",
        "            att_history = att_history.t()\n",
        "\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "        return to_feats"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OQVcxHgSqR8"
      },
      "source": [
        "## Social Aggregators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6F8WfobS4G5"
      },
      "source": [
        "class Social_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    Social Aggregator: for aggregating embeddings of social neighbors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, features, u2e, embed_dim, cuda=\"cpu\"):\n",
        "        super(Social_Aggregator, self).__init__()\n",
        "        \n",
        "        self.features = features\n",
        "        self.device = cuda\n",
        "        self.u2e = u2e\n",
        "        self.embed_dim = embed_dim\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, to_neighs):\n",
        "        embed_matrix = torch.empty(len(nodes), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "        for i in range(len(nodes)):\n",
        "            tmp_adj = to_neighs[i]\n",
        "            num_neighs = len(tmp_adj)\n",
        "            # \n",
        "            e_u = self.u2e.weight[list(tmp_adj)] # fast: user embedding \n",
        "            #slow: item-space user latent factor (item aggregation)\n",
        "            #feature_neigbhors = self.features(torch.LongTensor(list(tmp_adj)).to(self.device))\n",
        "            #e_u = torch.t(feature_neigbhors)\n",
        "\n",
        "            u_rep = self.u2e.weight[nodes[i]]\n",
        "\n",
        "            att_w = self.att(e_u, u_rep, num_neighs)\n",
        "            att_history = torch.mm(e_u.t(), att_w).t()\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "\n",
        "        return to_feats\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q2kLdSiTMMf"
      },
      "source": [
        "## UV Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2G-0gbTZuZ"
      },
      "source": [
        "class UV_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, history_uv_lists, history_r_lists, aggregator, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Encoder, self).__init__()\n",
        "        \n",
        "        self.features = features\n",
        "        self.uv = uv\n",
        "        self.history_uv_lists = history_uv_lists\n",
        "        self.history_r_lists = history_r_lists\n",
        "        self.aggregator = aggregator\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "        tmp_history_uv = []\n",
        "        tmp_history_r = []\n",
        "        for node in nodes:\n",
        "            tmp_history_uv.append(self.history_uv_lists[int(node)])\n",
        "            tmp_history_r.append(self.history_r_lists[int(node)])\n",
        "        neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r)  # user-item network\n",
        "        self_feats = self.features.weight[nodes]\n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqGTCqTPY8B0"
      },
      "source": [
        "## Social Aggregators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjHJ-WDiZD45"
      },
      "source": [
        "class Social_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, social_adj_lists, aggregator, base_model=None, cuda=\"cpu\"):\n",
        "        super(Social_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.social_adj_lists = social_adj_lists\n",
        "        self.aggregator = aggregator\n",
        "        if base_model != None:\n",
        "            self.base_model = base_model\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "\n",
        "        to_neighs = []\n",
        "        for node in nodes:\n",
        "            to_neighs.append(self.social_adj_lists[int(node)])\n",
        "        neigh_feats = self.aggregator.forward(nodes, to_neighs)  # user-user network\n",
        "\n",
        "        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)\n",
        "        self_feats = self_feats.t()\n",
        "        \n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz41sJwRsV7R"
      },
      "source": [
        "## GraphRec Instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB9zPtZvSGyh"
      },
      "source": [
        "class GraphRec(nn.Module):\n",
        "\n",
        "    def __init__(self, enc_u, enc_v_history, r2e):\n",
        "        super(GraphRec, self).__init__()\n",
        "        self.enc_u = enc_u\n",
        "        self.enc_v_history = enc_v_history\n",
        "        self.embed_dim = enc_u.embed_dim\n",
        "\n",
        "        self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
        "        self.w_uv3 = nn.Linear(16, 1)\n",
        "        self.r2e = r2e\n",
        "        self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn4 = nn.BatchNorm1d(16, momentum=0.5)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, nodes_u, nodes_v):\n",
        "        embeds_u = self.enc_u(nodes_u)\n",
        "        embeds_v = self.enc_v_history(nodes_v)\n",
        "\n",
        "        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
        "        x_u = F.dropout(x_u, training=self.training)\n",
        "        x_u = self.w_ur2(x_u)\n",
        "        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
        "        x_v = F.dropout(x_v, training=self.training)\n",
        "        x_v = self.w_vr2(x_v)\n",
        "\n",
        "        x_uv = torch.cat((x_u, x_v), 1)\n",
        "        x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.bn4(self.w_uv2(x)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        scores = self.w_uv3(x)\n",
        "        return scores.squeeze()\n",
        "\n",
        "    def loss(self, nodes_u, nodes_v, labels_list):\n",
        "        scores = self.forward(nodes_u, nodes_v)\n",
        "        return self.criterion(scores, labels_list)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5rXYK98SMPy"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, best_rmse, best_mae):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        batch_nodes_u, batch_nodes_v, labels_list = data\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(batch_nodes_u.to(device), batch_nodes_v.to(device), labels_list.to(device))\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            print('[%d, %5d] loss: %.3f, The best rmse/mae: %.6f / %.6f' % (\n",
        "                epoch, i, running_loss / 100, best_rmse, best_mae))\n",
        "            running_loss = 0.0\n",
        "    return 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzfrXeP2Sr6n"
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    tmp_pred = []\n",
        "    target = []\n",
        "    with torch.no_grad():\n",
        "        for test_u, test_v, tmp_target in test_loader:\n",
        "            test_u, test_v, tmp_target = test_u.to(device), test_v.to(device), tmp_target.to(device)\n",
        "            val_output = model.forward(test_u, test_v)\n",
        "            tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
        "            target.append(list(tmp_target.data.cpu().numpy()))\n",
        "    tmp_pred = np.array(sum(tmp_pred, []))\n",
        "    target = np.array(sum(target, []))\n",
        "    expected_rmse = sqrt(mean_squared_error(tmp_pred, target))\n",
        "    mae = mean_absolute_error(tmp_pred, target)\n",
        "    return expected_rmse, mae"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGSgS6DjSvz-",
        "outputId": "37a994b1-8f26-451f-a29a-cd7717a2b512"
      },
      "source": [
        "def main():\n",
        "    # Training settings\n",
        "    parser = argparse.ArgumentParser(description='Social Recommendation: GraphRec model')\n",
        "    parser.add_argument('--batch_size', type=int, default=128, metavar='N', help='input batch size for training')\n",
        "    parser.add_argument('--embed_dim', type=int, default=64, metavar='N', help='embedding size')\n",
        "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR', help='learning rate')\n",
        "    parser.add_argument('--test_batch_size', type=int, default=1000, metavar='N', help='input batch size for testing')\n",
        "    parser.add_argument('--epochs', type=int, default=100, metavar='N', help='number of epochs to train')\n",
        "    parser.add_argument(\"-f\", \"--file\", required=False) # Enable pickle file operations on Colabs\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "    use_cuda = False\n",
        "    if torch.cuda.is_available():\n",
        "        use_cuda = True\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    embed_dim = args.embed_dim\n",
        "    dir_data = './toy_dataset'\n",
        "\n",
        "    path_data = dir_data + \".pickle\"\n",
        "    data_file = open(path_data, 'rb')\n",
        "    history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, train_u, train_v, train_r, test_u, test_v, test_r, social_adj_lists, ratings_list = pickle.load(\n",
        "        data_file)\n",
        "    \"\"\"\n",
        "    ## toy dataset \n",
        "    history_u_lists, history_ur_lists:  user's purchased history (item set in training set), and his/her rating score (dict)\n",
        "    history_v_lists, history_vr_lists:  user set (in training set) who have interacted with the item, and rating score (dict)\n",
        "    \n",
        "    train_u, train_v, train_r: training_set (user, item, rating)\n",
        "    test_u, test_v, test_r: testing set (user, item, rating)\n",
        "    \n",
        "    # please add the validation set\n",
        "    \n",
        "    social_adj_lists: user's connected neighborhoods\n",
        "    ratings_list: rating value from 0.5 to 4.0 (8 opinion embeddings)\n",
        "    \"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v),\n",
        "                                              torch.FloatTensor(train_r))\n",
        "    testset = torch.utils.data.TensorDataset(torch.LongTensor(test_u), torch.LongTensor(test_v),\n",
        "                                             torch.FloatTensor(test_r))\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=True)\n",
        "    num_users = history_u_lists.__len__()\n",
        "    num_items = history_v_lists.__len__()\n",
        "    num_ratings = ratings_list.__len__()\n",
        "\n",
        "    u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
        "    v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
        "    r2e = nn.Embedding(num_ratings, embed_dim).to(device)\n",
        "\n",
        "    # user feature\n",
        "    # features: item * rating\n",
        "    agg_u_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=True)\n",
        "    enc_u_history = UV_Encoder(u2e, embed_dim, history_u_lists, history_ur_lists, agg_u_history, cuda=device, uv=True)\n",
        "    # neighobrs\n",
        "    agg_u_social = Social_Aggregator(lambda nodes: enc_u_history(nodes).t(), u2e, embed_dim, cuda=device)\n",
        "    enc_u = Social_Encoder(lambda nodes: enc_u_history(nodes).t(), embed_dim, social_adj_lists, agg_u_social,\n",
        "                           base_model=enc_u_history, cuda=device)\n",
        "\n",
        "    # item feature: user * rating\n",
        "    agg_v_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=False)\n",
        "    enc_v_history = UV_Encoder(v2e, embed_dim, history_v_lists, history_vr_lists, agg_v_history, cuda=device, uv=False)\n",
        "\n",
        "    # model\n",
        "    graphrec = GraphRec(enc_u, enc_v_history, r2e).to(device)\n",
        "    optimizer = torch.optim.RMSprop(graphrec.parameters(), lr=args.lr, alpha=0.9)\n",
        "\n",
        "    best_rmse = 9999.0\n",
        "    best_mae = 9999.0\n",
        "    endure_count = 0\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "\n",
        "        train(graphrec, device, train_loader, optimizer, epoch, best_rmse, best_mae)\n",
        "        expected_rmse, mae = test(graphrec, device, test_loader)\n",
        "        # please add the validation set to tune the hyper-parameters based on your datasets.\n",
        "\n",
        "        # early stopping (no validation set in toy dataset)\n",
        "        if best_rmse > expected_rmse:\n",
        "            best_rmse = expected_rmse\n",
        "            best_mae = mae\n",
        "            endure_count = 0\n",
        "        else:\n",
        "            endure_count += 1\n",
        "        print(\"rmse: %.4f, mae:%.4f \" % (expected_rmse, mae))\n",
        "\n",
        "        if endure_count > 5:\n",
        "            break\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UV aggregator cpu\n",
            "UV aggregator cpu\n",
            "[1,     0] loss: 0.110, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   100] loss: 8.485, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "rmse: 2.4402, mae:2.2788 \n",
            "[2,     0] loss: 0.056, The best rmse/mae: 2.440196 / 2.278831\n",
            "[2,   100] loss: 4.497, The best rmse/mae: 2.440196 / 2.278831\n",
            "rmse: 1.6202, mae:1.4245 \n",
            "[3,     0] loss: 0.031, The best rmse/mae: 1.620243 / 1.424518\n",
            "[3,   100] loss: 2.193, The best rmse/mae: 1.620243 / 1.424518\n",
            "rmse: 1.2454, mae:1.0394 \n",
            "[4,     0] loss: 0.013, The best rmse/mae: 1.245394 / 1.039425\n",
            "[4,   100] loss: 1.448, The best rmse/mae: 1.245394 / 1.039425\n",
            "rmse: 0.9682, mae:0.7700 \n",
            "[5,     0] loss: 0.014, The best rmse/mae: 0.968196 / 0.770029\n",
            "[5,   100] loss: 1.206, The best rmse/mae: 0.968196 / 0.770029\n",
            "rmse: 1.0077, mae:0.7832 \n",
            "[6,     0] loss: 0.014, The best rmse/mae: 0.968196 / 0.770029\n",
            "[6,   100] loss: 1.042, The best rmse/mae: 0.968196 / 0.770029\n",
            "rmse: 0.9332, mae:0.7272 \n",
            "[7,     0] loss: 0.010, The best rmse/mae: 0.933151 / 0.727195\n",
            "[7,   100] loss: 0.947, The best rmse/mae: 0.933151 / 0.727195\n",
            "rmse: 0.8412, mae:0.6724 \n",
            "[8,     0] loss: 0.008, The best rmse/mae: 0.841151 / 0.672444\n",
            "[8,   100] loss: 0.913, The best rmse/mae: 0.841151 / 0.672444\n",
            "rmse: 0.8441, mae:0.6493 \n",
            "[9,     0] loss: 0.008, The best rmse/mae: 0.841151 / 0.672444\n",
            "[9,   100] loss: 0.865, The best rmse/mae: 0.841151 / 0.672444\n",
            "rmse: 0.8623, mae:0.6515 \n",
            "[10,     0] loss: 0.009, The best rmse/mae: 0.841151 / 0.672444\n",
            "[10,   100] loss: 0.846, The best rmse/mae: 0.841151 / 0.672444\n",
            "rmse: 0.8177, mae:0.6395 \n",
            "[11,     0] loss: 0.008, The best rmse/mae: 0.817721 / 0.639530\n",
            "[11,   100] loss: 0.805, The best rmse/mae: 0.817721 / 0.639530\n",
            "rmse: 0.8261, mae:0.6435 \n",
            "[12,     0] loss: 0.008, The best rmse/mae: 0.817721 / 0.639530\n",
            "[12,   100] loss: 0.779, The best rmse/mae: 0.817721 / 0.639530\n",
            "rmse: 0.8971, mae:0.7004 \n",
            "[13,     0] loss: 0.007, The best rmse/mae: 0.817721 / 0.639530\n",
            "[13,   100] loss: 0.757, The best rmse/mae: 0.817721 / 0.639530\n",
            "rmse: 0.9102, mae:0.6749 \n",
            "[14,     0] loss: 0.008, The best rmse/mae: 0.817721 / 0.639530\n",
            "[14,   100] loss: 0.734, The best rmse/mae: 0.817721 / 0.639530\n",
            "rmse: 0.8178, mae:0.6278 \n",
            "[15,     0] loss: 0.008, The best rmse/mae: 0.817721 / 0.639530\n",
            "[15,   100] loss: 0.713, The best rmse/mae: 0.817721 / 0.639530\n",
            "rmse: 0.8056, mae:0.6254 \n",
            "[16,     0] loss: 0.007, The best rmse/mae: 0.805614 / 0.625413\n",
            "[16,   100] loss: 0.706, The best rmse/mae: 0.805614 / 0.625413\n",
            "rmse: 0.8199, mae:0.6267 \n",
            "[17,     0] loss: 0.007, The best rmse/mae: 0.805614 / 0.625413\n",
            "[17,   100] loss: 0.691, The best rmse/mae: 0.805614 / 0.625413\n",
            "rmse: 0.8118, mae:0.6244 \n",
            "[18,     0] loss: 0.005, The best rmse/mae: 0.805614 / 0.625413\n",
            "[18,   100] loss: 0.676, The best rmse/mae: 0.805614 / 0.625413\n",
            "rmse: 0.8331, mae:0.6307 \n",
            "[19,     0] loss: 0.007, The best rmse/mae: 0.805614 / 0.625413\n",
            "[19,   100] loss: 0.663, The best rmse/mae: 0.805614 / 0.625413\n",
            "rmse: 0.8138, mae:0.6249 \n",
            "[20,     0] loss: 0.005, The best rmse/mae: 0.805614 / 0.625413\n",
            "[20,   100] loss: 0.655, The best rmse/mae: 0.805614 / 0.625413\n",
            "rmse: 0.8106, mae:0.6415 \n",
            "[21,     0] loss: 0.006, The best rmse/mae: 0.805614 / 0.625413\n",
            "[21,   100] loss: 0.644, The best rmse/mae: 0.805614 / 0.625413\n",
            "rmse: 0.8154, mae:0.6248 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}